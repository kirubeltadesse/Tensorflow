{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn import datasets\n",
    "import tensorflow as tf\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\",\n",
    "           \"dis\", \"tax\", \"ptratio\", \"medv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set= pd.read_csv('../data/boston_train.csv', skipinitialspace=True,skiprows=1, names=COLUMNS)\n",
    "test_set= pd.read_csv('../data/boston_test.csv', skipinitialspace=True,skiprows=1, names=COLUMNS)\n",
    "prediction_set= pd.read_csv('../data/boston_predict.csv', skipinitialspace=True,skiprows=1, names=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_set.shape, test_set.shape, prediction_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\",\"age\", \"dis\", \"tax\", \"ptratio\"]\n",
    "LABEL = \"medv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(k) for k in FEATURES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.estimator.LinearRegressor(\n",
    "    feature_columns=feature_cols,\n",
    "    model_dir=\"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### instruction how to feed the data using pandas_input_fn.This object needs 5 parameters:\n",
    "* x:feature data\n",
    "* y:label data\n",
    "* batch_size:batch. By default 128\n",
    "* num_epoch: Number of epoch, by default 1\n",
    "* shuffle: Shuffle or not the data. By default, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to feed multiple times we use function get_input_in\n",
    "def get_input_fn(data_set, num_epochs=None, n_batch=128, shuffle=True):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "    x=pd.DataFrame({k:data_set[k].values for k in FEATURES}),\n",
    "    y = pd.Series(data_set[LABEL].values),\n",
    "    batch_size=n_batch,\n",
    "    num_epochs=num_epochs,\n",
    "    shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.train(input_fn=get_input_fn(training_set,\n",
    "                                     num_epochs=None,\n",
    "                                     n_batch=128,\n",
    "                                     shuffle=False), \n",
    "               steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = estimator.evaluate(\n",
    "    input_fn=get_input_fn(test_set,\n",
    "                         num_epochs=1,\n",
    "                         n_batch=128,\n",
    "                         shuffle=False)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss with the code below\n",
    "loss_score = ev[\"loss\"]\n",
    "print(\"Loss: {0:f}\".format(loss_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['medv'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = estimator.predict(\n",
    "    input_fn=get_input_fn(prediction_set,\n",
    "                          num_epochs=1,\n",
    "                          n_batch = 128,\n",
    "                          shuffle=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(p[\"predictions\"]for p in itertools.islice(y,6))\n",
    "print(\"Predictions: {}\".format(str(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_n = pd.read_csv(\"../data/boston_train.csv\").values\n",
    "test_set_n = pd.read_csv(\"../data/boston_test.csv\").values\n",
    "prediction_set_n = pd.read_csv(\"../data/boston_predict.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    X_train = df[:,:-3]\n",
    "    y_train = df[:,-3]\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = prepare_data(training_set_n)\n",
    "X_test, y_test = prepare_data(test_set_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude the last column from prediction dataset because it is Nan\n",
    "x_predict = prediction_set_n[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape, x_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column('x',shape=X_train.shape[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator as before\n",
    "estimator = tf.estimator.LinearRegressor(    \n",
    "         feature_columns=feature_columns,    \n",
    "         model_dir=\"train1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using numpy estimator to feed the model\n",
    "# train the estimator\n",
    "\n",
    "train_input = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': X_train},\n",
    "    y=y_train,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_epochs=None)\n",
    "estimator.train(input_fn=train_input,steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'x':X_test},\n",
    "    y=y_test,\n",
    "    shuffle=False,\n",
    "    batch_size=128,\n",
    "    num_epochs=1)\n",
    "estimator.evaluate(eval_input, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\":x_predict},\n",
    "    batch_size=128,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "y = estimator.predict(test_input)\n",
    "predictions = list(p[\"predictions\"]for p in itertools.islice(y,6))\n",
    "print(\"Predictions: {}\".format(str(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = '../data/boston_train.csv'\n",
    "df_eval = '../data/boston_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selected to be used\n",
    "COLUMNS = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\",\n",
    "                \"dis\", \"tax\", \"ptratio\", \"medv\"]\n",
    "# type of variable\n",
    "RECORDS_ALL = [[0.0], [0.0], [0.0], [0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the input_fn \n",
    "the function can be broken into three part:\n",
    "1. Import the data\n",
    "2. Create the iterator\n",
    "3. Consume the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(data_file, batch_size, num_epoch = None):\n",
    "    # Step 1\n",
    "    def parse_csv(value):\n",
    "        columns = tf.decode_csv(value, record_defaults=RECORDS_ALL)\n",
    "        features = dict(zip(COLUMNS,columns))\n",
    "        labels = features.pop('medv')\n",
    "        return features, labels\n",
    "    # Extract lines from input files using the Dataset API.\n",
    "    dataset = (tf.data.TextLineDataset(data_file)).skip(1).map(parse_csv)\n",
    "    \n",
    "    # Read text file\n",
    "    # Skip header row\n",
    "#     dataset.skip(1).map(parse_csv)\n",
    "    \n",
    "    dataset = dataset.repeat(num_epoch)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    # Step 3\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'crim': array([2.3004], dtype=float32), 'zn': array([0.], dtype=float32), 'indus': array([19.58], dtype=float32), 'nox': array([0.605], dtype=float32), 'rm': array([6.319], dtype=float32), 'age': array([96.1], dtype=float32), 'dis': array([2.1], dtype=float32), 'tax': array([403.], dtype=float32), 'ptratio': array([14.7], dtype=float32)}, array([23.8], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# Step 4 Consume the data\n",
    "next_batch = input_fn(df_train, batch_size=1, num_epoch=None)\n",
    "with tf.Session() as sess:\n",
    "    first_batch = sess.run(next_batch)\n",
    "    print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 Define the feature column\n",
    "X1 = tf.feature_column.numeric_column('crim')\n",
    "X2 = tf.feature_column.numeric_column('zn')\n",
    "X3 = tf.feature_column.numeric_column('indus')\n",
    "X4 = tf.feature_column.numeric_column('nox')\n",
    "X5 = tf.feature_column.numeric_column('rm')\n",
    "X6 = tf.feature_column.numeric_column('age')\n",
    "X7 = tf.feature_column.numeric_column('dis')\n",
    "X8 = tf.feature_column.numeric_column('tax')\n",
    "X9 = tf.feature_column.numeric_column('ptratio')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_columns = [X1,X2, X3, X4, X5, X6, X7, X8, X9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5) Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'train3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7130343d68>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearRegressor(feature_columns=base_columns,\n",
    "                                    model_dir='train3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kirubel/miniconda3/envs/CSLabs/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/kirubel/miniconda3/envs/CSLabs/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into train3/model.ckpt.\n",
      "INFO:tensorflow:loss = 83729.64, step = 1\n",
      "INFO:tensorflow:global_step/sec: 137.919\n",
      "INFO:tensorflow:loss = 13909.657, step = 101 (0.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.816\n",
      "INFO:tensorflow:loss = 12881.449, step = 201 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.666\n",
      "INFO:tensorflow:loss = 12391.541, step = 301 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.078\n",
      "INFO:tensorflow:loss = 12050.5625, step = 401 (0.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.744\n",
      "INFO:tensorflow:loss = 11766.134, step = 501 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.927\n",
      "INFO:tensorflow:loss = 11509.922, step = 601 (0.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.437\n",
      "INFO:tensorflow:loss = 11272.889, step = 701 (0.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.638\n",
      "INFO:tensorflow:loss = 11051.9795, step = 801 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.047\n",
      "INFO:tensorflow:loss = 10845.855, step = 901 (0.575 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into train3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5925.9873.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressor at 0x7f7130343588>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the estimator\n",
    "model.train(steps = 1000, \n",
    "           input_fn = lambda:input_fn(df_train,batch_size=128, num_epoch = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-20T14:41:35Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from train3/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-20-14:41:35\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 32.15896, global_step = 1000, label/mean = 22.08, loss = 3215.896, prediction/mean = 22.404533\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: train3/model.ckpt-1000\n",
      "   average_loss, was: 32.158958435058594\n",
      "   label/mean, was: 22.079999923706055\n",
      "   loss, was: 3215.89599609375\n",
      "   prediction/mean, was: 22.40453338623047\n",
      "   global_step, was: 1000\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(steps=None, input_fn=lambda: input_fn(df_eval,\n",
    "                                                              batch_size=128,\n",
    "                                                              num_epoch = 1))\n",
    "for key in results:\n",
    "    print(\"   {}, was: {}\".format(key, results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_input = {\n",
    "          'crim': [0.03359,5.09017,0.12650,0.05515,8.15174,0.24522],\n",
    "          'zn': [75.0,0.0,25.0,33.0,0.0,0.0],\n",
    "          'indus': [2.95,18.10,5.13,2.18,18.10,9.90],\n",
    "          'nox': [0.428,0.713,0.453,0.472,0.700,0.544],\n",
    "          'rm': [7.024,6.297,6.762,7.236,5.390,5.782],\n",
    "          'age': [15.8,91.8,43.4,41.1,98.9,71.7],\n",
    "          'dis': [5.4011,2.3682,7.9809,4.0220,1.7281,4.0317],\n",
    "          'tax': [252,666,284,222,666,304],\n",
    "          'ptratio': [18.3,20.2,19.7,18.4,20.2,18.4]\n",
    "     }\n",
    "def test_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensors(prediction_input)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict all our prediction_input\n",
    "pred_results = model.predict(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from train3/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "(0, {'predictions': array([32.297546], dtype=float32)})\n",
      "(1, {'predictions': array([18.96125], dtype=float32)})\n",
      "(2, {'predictions': array([27.270979], dtype=float32)})\n",
      "(3, {'predictions': array([29.299236], dtype=float32)})\n",
      "(4, {'predictions': array([16.436684], dtype=float32)})\n",
      "(5, {'predictions': array([21.460876], dtype=float32)})\n"
     ]
    }
   ],
   "source": [
    "for pred in enumerate(pred_results):\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
